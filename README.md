<div align="center">
    <a href="https://github.com/YousefIbrahimismail/Project-README-Template/stargazers"><img alt="GitHub stars" src="https://img.shields.io/github/stars/YousefIbrahimismail/Project-README-Template?color=yellow&label=Project%20Stars&style=for-the-badge"></a>
    <a href="https://github.com/YousefIbrahimismail/Project-README-Template/issues"><img alt="GitHub issues" src="https://img.shields.io/github/issues/YousefIbrahimismail/Project-README-Template?color=brightgreen&label=issues&style=for-the-badge"></a>
    <a href="https://github.com/YousefIbrahimismail/Project-README-Template/network"><img alt="GitHub forks" src="https://img.shields.io/github/forks/YousefIbrahimismail/Project-README-Template?color=9cf&label=forks&style=for-the-badge"></a>
</div>
<br>

<div align="center">
    <a href="CTRL-HACK-DEL" target="_blank">
        <img src="https://user-images.githubusercontent.com/59213365/198116794-365cd9b5-e705-4111-a249-85ed713b9c87.jpg" 
        alt="Logo" height="300" width="auto">
    </a>
</div>

<div align="center">
<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&size=22&duration=4000&pause=5000&background=FFFFFF00&center=true&vCenter=true&multiline=true&width=435&lines=Sign-Language-AI-Model">
</div>

## Table of Contents<!-- Optional -->
<dev align="center">
<table align="center">
        <tr>
            <td><a href="#about">About</a></td>        
            <td><a href="#how-to-use-this-project">Getting started</td>
            <td><a href="#demo">Demo</a></td>
        </tr>
        <tr>
            <td><a href="#contributors">Contributors</a></td>
            <td><a href="#acknowledgments">Acknowledgments</a></td>
        </tr>
</table>
</dev>


## About
The idea for AI Sign Language was inspired by the need for accessible and interactive resources for people who want to learn sign language, whether for personal interest, professional development, or to communicate with loved ones who are Deaf or hard of hearing. Traditional learning resources often require in-person instruction or expensive programs, which aren’t feasible for everyone. We wanted to leverage AI and machine learning to make sign language learning more interactive, accessible, and fun for learners.

AI Sign Language provides an interactive platform where users can learn American Sign Language (ASL) through AI-driven video analysis, and real-time feedback. Users can learn simple sign positions and then practice by recording through their webcam. The AI system analyzes the user's gestures, compares them with correct signing techniques, and improve accuracy.

## How to use this project<!-- Required -->
- Clone the main and backend branch
- Install node modules and enter npm start to run the website
- Run keypoint_classifier.ipynb and once finished, run Main.py


## Demo<!-- Required -->
![Demo Photo](src/photos/image.png)
![Demo Photo](src/photos/image2.png)


<p align="right"><a href="#how-to-use-this-project">back to top ⬆️</a></p>

## Contributors<!-- Required -->

<a href="https://github.com/imanoob1118/CTRL-HACK-DEL/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=imanoob1118/CTRL-HACK-DEL" />
</a>

- Made with [contrib.rocks](https://contrib.rocks).


## Acknowledgments<!-- Optional -->
I would like to give acknowledgements to <a href="https://www.youtube.com/watch?v=a99p_fAr6e4&list=PL0FM467k5KSyt5o3ro2fyQGt-6zRkHXRv"> Ivan Goncharov </a> on his video on Custom Hand Gesture Recognition with Hand Landmarks Using Google’s Mediapipe + OpenCV in Python. Thanks to <a href="https://github.com/kinivi/hand-gesture-recognition-mediapipe">Nikita Kiselov</a> for translating the github. And thank you to <a href="https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe">KazuhitoTakahashi</a> for creating the original repostitory
 
<p align="right"><a href="#how-to-use-this-project">back to top ⬆️</a></p>


